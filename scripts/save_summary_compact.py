#!/usr/bin/env python3
import json
import os
import re
import sys
import textwrap
import subprocess

from anthropic import Anthropic
from datetime import datetime

# === ç”¨äºç¾åŒ–è¾“å‡ºçš„ ANSI é¢œè‰²ä»£ç  ===
class Colors:
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'  # æ¨èç”¨è¿™ä¸ªé¢œè‰²åšæµå¼è¾“å‡º
    GREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'   # é‡ç½®é¢œè‰²
    BOLD = '\033[1m'

# /save-summary ä¸å†éœ€è¦å‚æ•°
# CMD_RE = re.compile(r"^\s*/(?:context-retrieval:)?save-summary\s*$")


FILE_BLOCK_RE = re.compile(
    r"===FILE:index\.json===\s*(?P<index>.*?)\s*===END_FILE===\s*"
    r"===FILE:resolutions\.ndjson===\s*(?P<ndjson>.*?)\s*===END_FILE===",
    re.DOTALL,
)

def eprint(msg: str) -> None:
    sys.stderr.write(msg.rstrip() + "\n")


def tail_lines(path: str, max_lines: int = 4000) -> list[str]:
    try:
        with open(path, "r", encoding="utf-8", errors="replace") as f:
            return f.readlines()[-max_lines:]
    except FileNotFoundError:
        return []

def parse_jsonl_lines(lines: list[str]) -> list[dict]:
    out = []
    for ln in lines:
        ln = ln.strip()
        if not ln:
            continue
        try:
            out.append(json.loads(ln))
        except Exception:
            pass
    return out

def collect_text_from_any(node, out: list[str]) -> None:
    """
    é€’å½’ä»ä»»æ„ç»“æ„é‡Œæ”¶é›†æ–‡æœ¬ï¼š
    - str
    - list
    - dict: æ”¯æŒ {"type":"text","text":...} / {"type":"tool_result","content":[...]} / {"message":...} ç­‰
    """
    if node is None:
        return
    if isinstance(node, str):
        s = node.strip()
        if s:
            out.append(s)
        return
    if isinstance(node, list):
        for item in node:
            collect_text_from_any(item, out)
        return
    if isinstance(node, dict):
        # å¸¸è§æ–‡æœ¬å—
        if node.get("type") == "text" and isinstance(node.get("text"), str):
            s = node["text"].strip()
            if s:
                out.append(s)
        # é€’å½’å¸¸è§å®¹å™¨å­—æ®µ
        if "content" in node:
            collect_text_from_any(node["content"], out)
        if "message" in node:
            collect_text_from_any(node["message"], out)
        if "input" in node:
            # tool_use çš„ input é‡Œå¯èƒ½æœ‰ prompt/description
            collect_text_from_any(node["input"], out)

        return

def extract_text_from_message_obj(msg_obj) -> str:
    """
    å…¼å®¹ï¼š
    - message.content æ˜¯ str
    - message.content æ˜¯ listï¼Œå…¶ä¸­åŒ…å« text / tool_result / å…¶ä»–åµŒå¥—ç»“æ„
    """
    if not isinstance(msg_obj, dict):
        return ""
    buf: list[str] = []
    collect_text_from_any(msg_obj.get("content"), buf)
    return "\n".join([x for x in buf if x]).strip()

def build_session_material(events: list[dict], max_chars: int = 60000) -> str:
    """
    ç›®æ ‡ï¼šæŠŠâ€œå¤æ‚ transcriptâ€çš„ä¸»è¦ä¿¡æ¯æŠ“å…¨ï¼š
    - summary äº‹ä»¶
    - æ™®é€šå¯¹è¯ï¼ˆuser/assistantï¼‰
    - tool_useï¼ˆå·¥å…·è°ƒç”¨ï¼šname/id/input é‡Œçš„ description/promptï¼‰
    - tool_resultï¼ˆå·¥å…·è¾“å‡ºçš„å¤§æ®µæ–‡æœ¬ï¼‰
    - é¡¶å±‚ toolUseResultï¼ˆç»Ÿè®¡ + contentï¼‰
    """
    summaries: list[str] = []
    dialogue: list[str] = []
    tool_uses: list[str] = []
    tool_results: list[str] = []
    tool_stats: list[str] = []

    for e in events:
        if not isinstance(e, dict):
            continue

        # 1) summary
        if e.get("type") == "summary" and isinstance(e.get("summary"), str):
            summaries.append(e["summary"].strip())
            continue

        # 2) tool_useï¼ˆé€šå¸¸åœ¨ assistant.message.content[] é‡Œï¼‰
        if e.get("type") == "assistant":
            msg = e.get("message") if isinstance(e.get("message"), dict) else {}
            content = msg.get("content")
            if isinstance(content, list):
                for item in content:
                    if isinstance(item, dict) and item.get("type") == "tool_use":
                        name = item.get("name")
                        tid = item.get("id")
                        inp = item.get("input")
                        desc = ""
                        if isinstance(inp, dict):
                            if isinstance(inp.get("description"), str):
                                desc = inp["description"]
                            elif isinstance(inp.get("prompt"), str):
                                desc = inp["prompt"]
                        desc = (desc or "").strip().replace("\r", "")
                        tool_uses.append(f"- tool_use: {name} ({tid}) {desc[:600]}")

        # 3) tool_resultï¼ˆå¤æ‚å—é€šå¸¸åœ¨ type:"user" çš„ message.content[] é‡Œï¼‰
        if e.get("type") == "user":
            msg = e.get("message") if isinstance(e.get("message"), dict) else {}
            content = msg.get("content")
            if isinstance(content, list):
                for item in content:
                    if isinstance(item, dict) and item.get("type") == "tool_result":
                        buf: list[str] = []
                        collect_text_from_any(item.get("content"), buf)
                        block = "\n".join([x for x in buf if x]).strip()
                        if block:
                            tool_results.append(block)

        # 4) æ™®é€šå¯¹è¯ï¼ˆuser/assistantï¼‰
        t = e.get("type")
        if t in ("user", "assistant"):
            msg_obj = e.get("message")
            if isinstance(msg_obj, dict):
                role = msg_obj.get("role") or t
                if isinstance(role, str):
                    role = role.strip()
                else:
                    role = t
                text = extract_text_from_message_obj(msg_obj)
                if text:
                    dialogue.append(f"{role}: {text}")

        # 5) é¡¶å±‚ toolUseResultï¼ˆç»Ÿè®¡ + contentï¼‰
        tur = e.get("toolUseResult")
        if isinstance(tur, dict):
            status = tur.get("status")
            agent_id = tur.get("agentId")
            total_tokens = tur.get("totalTokens")
            duration = tur.get("totalDurationMs")
            tool_stats.append(
                f"- toolUseResult: status={status}, agentId={agent_id}, totalTokens={total_tokens}, durationMs={duration}"
            )
            buf: list[str] = []
            collect_text_from_any(tur.get("content"), buf)
            block = "\n".join([x for x in buf if x]).strip()
            if block:
                tool_results.append(block)

    material: list[str] = []

    if summaries:
        material.append("ã€summary äº‹ä»¶ã€‘")
        material += [f"- {s}" for s in summaries[-80:]]
        material.append("")

    if tool_uses:
        material.append("ã€tool_use äº‹ä»¶ï¼ˆæˆªå–ï¼‰ã€‘")
        material += tool_uses[-120:]
        material.append("")

    if tool_stats:
        material.append("ã€toolUseResult ç»Ÿè®¡ã€‘")
        material += tool_stats[-120:]
        material.append("")

    if tool_results:
        material.append("ã€tool_result / toolUseResult è¾“å‡ºï¼ˆé‡ç‚¹ï¼Œæˆªå–ï¼‰ã€‘")
        for block in tool_results[-120:]:
            material.append(block[:20000])
            material.append("\n---\n")

    if dialogue:
        material.append("ã€æœ€è¿‘å¯¹è¯ï¼ˆæˆªå–ï¼‰ã€‘")
        material += dialogue[-120:]

    blob = "\n".join(material).strip()
    return blob[-max_chars:]


def load_project_settings() -> dict:
    """
    åªä»ç”¨æˆ·çº§ ~/.claude/settings.json åŠ è½½é…ç½®
    """
    settings_path = os.path.expanduser("~/.claude/settings.json")

    if not os.path.isfile(settings_path):
        sys.stderr.write(
            f"âš ï¸ ç”¨æˆ·çº§é…ç½®ä¸å­˜åœ¨: {settings_path}\n"
        )
        return {}

    try:
        with open(settings_path, "r", encoding="utf-8") as f:
            settings = json.load(f)
            sys.stderr.write(
                f"âœ… Loaded user settings from: {settings_path}\n"
            )
            return settings
    except Exception as e:
        sys.stderr.write(
            f"âš ï¸ è¯»å– {settings_path} å¤±è´¥: {e}\n"
        )
        return {}


def run_claude_p(prompt: str, input_text: str) -> str:
    """
    ä½¿ç”¨ Anthropic SDK è°ƒç”¨è‡ªå®šä¹‰ API æ¥å£
    æ›¿æ¢äº†åŸæœ¬ä¸ç¨³å®šçš„å‘½ä»¤è¡Œè°ƒç”¨æ–¹å¼
    """
    
    # # === é…ç½®åŒºåŸŸ (æ ¹æ®ä½ æä¾›çš„ Settings å¡«å…¥) ===
    # # å¯¹åº” settings: ANTHROPIC_AUTH_TOKEN
    # API_KEY = "alkjhiu8970876iulkhio^&khh" 
    
    # # å¯¹åº” settings: ANTHROPIC_BASE_URL
    # BASE_URL = "http://azure.711511.xyz:8317"
    
    # # å¯¹åº” settings: ANTHROPIC_REASONING_MODEL
    # # æ³¨æ„ï¼šä½ è¯´è¦ç”¨è¿™ä¸ª thinking æ¨¡å‹
    # MODEL_NAME = "gemini-claude-opus-4-5-thinking"
    
    # # ===========================================

    """
    è¯»å– settings.json é…ç½®å¹¶ä½¿ç”¨ Anthropic SDK è°ƒç”¨ API
    """
    
    # === 1. ä» settings.json åŠ è½½é…ç½® ===
    settings = load_project_settings()
    
    # ã€å…³é”®ä¿®æ”¹ç‚¹ã€‘ï¼šé…ç½®åœ¨ "env" å¯¹è±¡ä¸‹é¢ï¼Œè€Œä¸æ˜¯æ ¹èŠ‚ç‚¹
    # ä½¿ç”¨ .get("env", {}) ç¡®ä¿å³ä½¿ env ä¸å­˜åœ¨ä¹Ÿä¸ä¼šæŠ¥é”™ï¼Œè€Œæ˜¯è¿”å›ç©ºå­—å…¸
    env_config = settings.get("env", {})
    
    # ä» env_config ä¸­æå–é…ç½®
    api_key = env_config.get("ANTHROPIC_AUTH_TOKEN")
    base_url = env_config.get("ANTHROPIC_BASE_URL")
    
    # æ¨¡å‹åç§°ä¹Ÿä¼˜å…ˆä» env ä¸­è¯»å–
    model_name = env_config.get("ANTHROPIC_REASONING_MODEL", "gemini-claude-opus-4-5-thinking")
    
    # === 2. æ ¡éªŒå¿…è¦é…ç½® ===
    if not api_key:
        raise ValueError("settings.json çš„ 'env' ä¸­ç¼ºå°‘ 'ANTHROPIC_AUTH_TOKEN'ã€‚")
    
    if not base_url:
        raise ValueError("settings.json çš„ 'env' ä¸­ç¼ºå°‘ 'ANTHROPIC_BASE_URL'ã€‚")
    # 1. åˆå§‹åŒ–å®¢æˆ·ç«¯
    try:
        client = Anthropic(
            api_key=api_key,
            base_url=base_url,
        )
    except Exception as e:
        raise RuntimeError(f"Anthropic SDK åˆå§‹åŒ–å¤±è´¥: {e}")

    # 2. æ„é€ æ¶ˆæ¯
    # ä¸ºäº†å…¼å®¹æ€§æœ€å¼ºï¼Œæˆ‘ä»¬å°† Promptï¼ˆæŒ‡ä»¤ï¼‰å’Œ input_textï¼ˆç´ æï¼‰åˆå¹¶å‘ç»™ User
    full_content = f"{prompt}\n\n{input_text}"

    # 3. å‘é€è¯·æ±‚
    try:
        response = client.messages.create(
            model=model_name,
            max_tokens=8192,  # è®¾ç½®è¶³å¤Ÿå¤§çš„è¾“å‡º Tokenï¼Œé˜²æ­¢ JSON è¢«æˆªæ–­
            temperature=0.1,  # å½’æ¡£ä»»åŠ¡å»ºè®®ä½æ¸©åº¦ï¼Œä¿è¯æ ¼å¼ç¨³å®š
            messages=[
                {
                    "role": "user", 
                    "content": full_content
                }
            ]
        )
        
        # 4. è·å–å¹¶è¿”å›æ–‡æœ¬
        # Anthropic çš„è¿”å›ç»“æ„é€šå¸¸æ˜¯ content[0].text
        if not response.content:
            raise RuntimeError("API è¿”å›äº†ç©º content")
            
        return response.content[0].text

    except Exception as e:
        # è¿™é‡Œä¼šæ•è·å¦‚ 401(è®¤è¯å¤±è´¥), 400(è¯·æ±‚è¿‡é•¿), 500(æœåŠ¡å™¨é”™) ç­‰æ‰€æœ‰ API é”™è¯¯
        # å¹¶å°†é”™è¯¯ä¿¡æ¯æŠ›å‡ºï¼Œè¿™æ ·ä½ çš„ debug æ–‡ä»¶é‡Œå°±èƒ½çœ‹åˆ°å…·ä½“çš„ API æŠ¥é”™åŸå› äº†
        raise RuntimeError(f"API è¯·æ±‚å‘ç”Ÿé”™è¯¯: {str(e)}")



def normalize_index(obj: dict) -> dict:
    """
    é˜²æ­¢æ¨¡å‹å¶å‘æ¼å­—æ®µå¯¼è‡´åç»­åˆå¹¶å´©æºƒï¼šä¿è¯ schema å­—æ®µå­˜åœ¨ã€‚
    """
    if not isinstance(obj, dict):
        obj = {}
    obj.setdefault("context_version", "v2")
    obj.setdefault("project", "unknown")
    obj.setdefault("current_state", "")
    obj.setdefault("goals", [])
    obj.setdefault("constraints", [])
    obj.setdefault("environment", {"os": None, "runtime": None, "tools": [], "paths": []})
    obj.setdefault("verified_facts", [])
    obj.setdefault("next_actions", [])
    obj.setdefault("detail_index", {"resolutions": []})
    if not isinstance(obj.get("detail_index"), dict):
        obj["detail_index"] = {"resolutions": []}
    obj["detail_index"].setdefault("resolutions", [])
    if not isinstance(obj["detail_index"]["resolutions"], list):
        obj["detail_index"]["resolutions"] = []
    return obj

def unique_list_merge(a, b) -> list:
    """
    åˆå¹¶ä¸¤ä¸ª listï¼ŒæŒ‰ json åºåˆ—åŒ–åçš„ key å»é‡ï¼Œä¿æŒé¡ºåºï¼ˆå…ˆ a å bï¼‰
    """
    out = []
    seen = set()
    for arr in (a, b):
        if not isinstance(arr, list):
            continue
        for item in arr:
            try:
                k = json.dumps(item, ensure_ascii=False, sort_keys=True)
            except Exception:
                k = str(item)
            if k in seen:
                continue
            seen.add(k)
            out.append(item)
    return out

def merge_resolution_index_items(existing_items: list, incoming_items: list) -> list:
    """
    åˆå¹¶ detail_index.resolutionsï¼šæŒ‰ id å»é‡ï¼ˆid ä½œä¸ºç£ç›˜ä¸»é”®ï¼‰ã€‚
    """
    out = []
    seen = set()
    for it in (existing_items or []):
        if isinstance(it, dict) and isinstance(it.get("id"), str):
            rid = it["id"]
            if rid not in seen:
                out.append(it)
                seen.add(rid)
    for it in (incoming_items or []):
        if isinstance(it, dict) and isinstance(it.get("id"), str):
            rid = it["id"]
            if rid not in seen:
                out.append(it)
                seen.add(rid)
    return out

def allocate_next_res_id(res_dir: str, reserved: set[str]) -> str:
    os.makedirs(res_dir, exist_ok=True)
    existing = set()
    for name in os.listdir(res_dir):
        if name.startswith("res-") and name.endswith(".json"):
            existing.add(name[:-5])
    n = 1
    while True:
        rid = f"res-{n:03d}"
        if rid not in existing and rid not in reserved:
            reserved.add(rid)
            return rid
        n += 1

def parse_model_output_to_context(out_text: str, claude_dir: str) -> dict:
    """
    è§£ææ¨¡å‹è¾“å‡ºçš„ä¸¤ä¸ªæ–‡ä»¶å—ï¼Œå¹¶è½ç›˜åˆ°ï¼š
    - {claude_dir}/context/index.json
    - {claude_dir}/context/resolutions/res-00x.json
    è¿”å› index.json çš„ dict
    """
    m = FILE_BLOCK_RE.search(out_text)
    if not m:
        raise ValueError("æ¨¡å‹è¾“å‡ºä¸ç¬¦åˆé¢„æœŸåˆ†éš”ç¬¦æ ¼å¼ï¼ˆæœªæ‰¾åˆ° index.json / resolutions.ndjson æ–‡ä»¶å—ï¼‰")

    incoming_index = normalize_index(json.loads(m.group("index").strip()))

    ndjson_text = m.group("ndjson").strip()


    context_dir = os.path.join(claude_dir, "context")
    res_dir = os.path.join(context_dir, "resolutions")
    os.makedirs(res_dir, exist_ok=True)

    index_path = os.path.join(context_dir, "index.json")


    # 1) è¯»å·²æœ‰ indexï¼ˆç”¨äºåˆå¹¶ï¼‰
    existing_index = None
    if os.path.exists(index_path):
        try:
            with open(index_path, "r", encoding="utf-8") as f:
                existing_index = normalize_index(json.load(f))
        except Exception:
            existing_index = None

    # 2) é€è¡Œå†™å…¥ resolutionsï¼ˆè¿½åŠ å¼ï¼Œé¿å…è¦†ç›–ï¼‰
    id_remap: dict[str, str] = {}    # æ¨¡å‹id -> å®é™…è½ç›˜idï¼ˆå†²çªæ—¶ï¼‰
    written_ids: list[str] = []
    reserved_ids: set[str] = set()


    lines = [ln.strip() for ln in ndjson_text.splitlines() if ln.strip()]
    for ln in lines:
        obj = json.loads(ln)
        rid = obj.get("id")
        if not isinstance(rid, str) or not rid.startswith("res-"):
            raise ValueError(f"resolution è¡Œç¼ºå°‘åˆæ³• idï¼š{rid!r}")
       
        out_file = os.path.join(res_dir, f"{rid}.json")
        if os.path.exists(out_file) or rid in reserved_ids:
            new_rid = allocate_next_res_id(res_dir, reserved_ids)

            id_remap[rid] = new_rid
            rid = new_rid
            obj["id"] = rid
            out_file = os.path.join(res_dir, f"{rid}.json")
        else:
            reserved_ids.add(rid)


        with open(out_file, "w", encoding="utf-8") as f:

            json.dump(obj, f, ensure_ascii=False, indent=2)
            f.write("\n")


        written_ids.append(rid)


    # 3) æŠŠ incoming_index.detail_index.resolutions é‡Œçš„ id æŒ‰ remap ä¿®æ­£
    incoming_items = incoming_index.get("detail_index", {}).get("resolutions", [])
    if isinstance(incoming_items, list):
        for it in incoming_items:
            if isinstance(it, dict) and isinstance(it.get("id"), str):
                old = it["id"]
                if old in id_remap:
                    it["id"] = id_remap[old]

    # å¦‚æœæ¨¡å‹æ²¡è¾“å‡º detail_indexï¼ˆæˆ–ç©ºï¼‰ï¼Œä½†æˆ‘ä»¬ç¡®å®å†™äº† resolutionsï¼Œåˆ™è¡¥æœ€å°ç›®å½•é¡¹
    if (not isinstance(incoming_items, list) or not incoming_items) and written_ids:
        incoming_index["detail_index"]["resolutions"] = []
        for rid in written_ids:
            incoming_index["detail_index"]["resolutions"].append({

                "id": rid,
                "problem_signature": "",
                "summary": "",
                "tags": [],
                "artifacts_touched": [],
            })


    # 4) åˆå¹¶ indexï¼ˆç›®å½•æ°¸ä¸ä¸¢ï¼‰
    if existing_index:
        merged = existing_index

        # æœ€æ–°è¦†ç›–ï¼ˆä»£è¡¨å½“å‰çŠ¶æ€ï¼‰
        merged["project"] = incoming_index.get("project", merged.get("project"))
        merged["current_state"] = incoming_index.get("current_state", merged.get("current_state"))
        merged["next_actions"] = incoming_index.get("next_actions", merged.get("next_actions"))

        # å¹¶é›†åˆå¹¶ï¼ˆä¸ä¸¢å†å²ï¼‰
        merged["goals"] = unique_list_merge(merged.get("goals", []), incoming_index.get("goals", []))
        merged["constraints"] = unique_list_merge(merged.get("constraints", []), incoming_index.get("constraints", []))
        merged["verified_facts"] = unique_list_merge(merged.get("verified_facts", []), incoming_index.get("verified_facts", []))

        # environment åˆå¹¶ï¼ˆos/runtime æœ€æ–°è¦†ç›–ï¼›tools/paths å¹¶é›†ï¼‰
        env_old = merged.get("environment") if isinstance(merged.get("environment"), dict) else {}
        env_new = incoming_index.get("environment") if isinstance(incoming_index.get("environment"), dict) else {}
        env = {
            "os": env_new.get("os", env_old.get("os")),
            "runtime": env_new.get("runtime", env_old.get("runtime")),
            "tools": unique_list_merge(env_old.get("tools", []), env_new.get("tools", [])),
            "paths": unique_list_merge(env_old.get("paths", []), env_new.get("paths", [])),
        }
        merged["environment"] = env

        merged["detail_index"]["resolutions"] = merge_resolution_index_items(
            merged.get("detail_index", {}).get("resolutions", []),
            incoming_index.get("detail_index", {}).get("resolutions", []),
        )
        final_index = merged
    else:
        final_index = incoming_index

    # 5) å†™å› index.jsonï¼ˆè¿™æ˜¯â€œèšåˆç›®å½•â€çš„æœ€æ–°ç‰ˆæœ¬ï¼Œä¸ä¼šåˆ é™¤æ—§æ¡ç›®ï¼‰
    os.makedirs(context_dir, exist_ok=True)
    with open(index_path, "w", encoding="utf-8") as f:
        json.dump(final_index, f, ensure_ascii=False, indent=2)
        f.write("\n")

    return final_index


def main() -> None:
    raw_stdin = sys.stdin.read()

    try:
        data = json.loads(raw_stdin) if raw_stdin.strip() else {}
    except Exception as ex:
        eprint(f"âŒ hook stdin ä¸æ˜¯åˆæ³• JSONï¼š{ex}")
        sys.exit(2)

    # user_prompt = (data.get("prompt") or "").strip()
    # m = CMD_RE.match(user_prompt)
    # if not m:
    #     sys.exit(0)


    # æ›´ç¨³ï¼šä¼˜å…ˆé¡¹ç›®æ ¹ï¼Œå† fallback åˆ° cwd
    base_dir = (os.environ.get("CLAUDE_PROJECT_DIR") or data.get("cwd") or os.getcwd())

    claude_dir = os.path.join(base_dir, ".claude")
    context_dir = os.path.join(claude_dir, "context")
    debug_dir = os.path.join(context_dir, "debug")
    os.makedirs(debug_dir, exist_ok=True)


    transcript_path = os.path.expanduser(data.get("transcript_path", "") or "")
    lines = tail_lines(transcript_path, max_lines=8000)
    events = parse_jsonl_lines(lines)
    material = build_session_material(events)

    # ä½ çš„â€œå¯¹è¯å½’æ¡£å™¨â€æç¤ºè¯ï¼ˆä¿æŒä½ ç°åœ¨çš„ç‰ˆæœ¬ï¼‰
    summary_prompt = textwrap.dedent("""\
ä½ æ˜¯ä¸€ä¸ªâ€œå¯¹è¯å½’æ¡£å™¨ï¼ˆConversation Archivistï¼‰â€ï¼Œè´Ÿè´£æŠŠç”¨æˆ·ä¸ç¼–ç¨‹å·¥å…·/Agent çš„é•¿å¯¹è¯ï¼Œæç‚¼ä¸ºå¯å¤ç”¨çš„å·¥ç¨‹ä¸Šä¸‹æ–‡ã€‚
ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯ä¸¤ä¸ªæ–‡ä»¶ï¼šindex.json å’Œ resolutions.ndjsonï¼Œä¸”å¿…é¡»ä¸¥æ ¼éµå®ˆä¸‹é¢çš„æ ¼å¼è¦æ±‚ï¼Œä¾¿äºç¨‹åºåç»­æ‹†åˆ†æˆç›®å½•ä¸å•æ–‡ä»¶ã€‚

ã€è¾“å…¥ã€‘
ç”¨æˆ·å°†æä¾›ä¸€æ®µé•¿å¯¹è¯æ–‡æœ¬ï¼Œå¯èƒ½åŒ…å«ï¼š
- ç›®æ ‡æè¿°ã€çº¦æŸã€ç¯å¢ƒä¿¡æ¯
- å¤šæ¬¡å¤±è´¥ä¸ä¿®å¤å°è¯•ï¼ˆæ—¥å¿—ï¼‰
- æœ€ç»ˆæˆåŠŸçš„æ–¹æ¡ˆï¼ˆéå¸¸é‡è¦ï¼‰
- å¯¹å¤šä¸ªä»£ç /é…ç½®æ–‡ä»¶çš„ä¿®æ”¹ç‚¹ï¼ˆä¸éœ€è¦è´´å…¨æ–‡ï¼‰
- éªŒè¯æ­¥éª¤ä¸ç»“æœ

ã€ä½ è¦åšçš„äº‹ã€‘
1) è¯†åˆ«â€œé¡¹ç›®/ä»»åŠ¡â€çš„å½“å‰ç›®æ ‡ä¸çŠ¶æ€ï¼ˆcurrent_stateï¼‰
2) æå–â€œå·²éªŒè¯äº‹å®â€ï¼ˆverified_factsï¼‰
3) ä»åå¤å°è¯•ä¸­æç‚¼â€œæœ€ç»ˆæ”¹å¯¹çš„è§£å†³æ–¹æ¡ˆå‰§æœ¬ï¼ˆresolutionï¼‰â€
   - æ¯ä¸ª resolution å¿…é¡»èƒ½è¢«å¤ç°ï¼šåŒ…å« final_fix æ­¥éª¤ã€verification æ£€æŸ¥ç‚¹ã€why_it_works
   - å¿…é¡»æå– 1-3 æ¡ anti_patternsï¼ˆèµ°è¿‡ä½†æ²¡ç”¨/æœ‰å‘ï¼‰
4) ä¸ºæ¯æ¡ resolution ç”Ÿæˆç¨³å®šå¯æ£€ç´¢çš„ problem_signatureï¼ˆå°½é‡æ¥è‡ªæ—¥å¿—ä¸­çš„ç¨³å®šæŠ¥é”™ç‰‡æ®µ/å…³é”®è¯ï¼‰
5) ä¸è¦è¾“å‡ºä»»ä½•æ–‡ä»¶å…¨æ–‡å†…å®¹ï¼›åªè®°å½•å…³é”®æ”¹åŠ¨ç‚¹ä¸è§¦è¾¾æ–‡ä»¶ï¼ˆartifacts_touchedï¼‰ï¼Œè®©ç¼–ç¨‹å·¥å…·è‡ªè¡Œè¯»å–ã€‚

ã€è¾“å‡ºè¦æ±‚ - æ€»ä½“ã€‘
- åªè¾“å‡ºä¸¤ä¸ªâ€œæ–‡ä»¶å—â€ï¼ŒæŒ‰å¦‚ä¸‹åˆ†éš”ç¬¦è¾“å‡ºï¼Œæ–¹ä¾¿ç¨‹åºæ‹†åˆ†ï¼š
  ===FILE:index.json===
  <è¿™é‡Œæ˜¯å®Œæ•´ JSON>
  ===END_FILE===
  ===FILE:resolutions.ndjson===
  <è¿™é‡Œæ˜¯ NDJSONï¼Œæ¯è¡Œä¸€ä¸ª JSONå¯¹è±¡>
  ===END_FILE===
- é™¤è¿™ä¸¤ä¸ªæ–‡ä»¶å—ä¹‹å¤–ï¼Œä¸å…è®¸è¾“å‡ºä»»ä½•é¢å¤–æ–‡å­—ã€è§£é‡Šã€markdownã€ä»£ç å—ã€‚

ã€index.json Schemaã€‘
index.json å¿…é¡»æ˜¯ä¸¥æ ¼ JSON å¯¹è±¡ï¼Œå­—æ®µå¦‚ä¸‹ï¼ˆå¯ä¸ºç©ºä½†å¿…é¡»å­˜åœ¨ï¼‰ï¼š
{
  "context_version": "v2",
  "project": "<string: é¡¹ç›®å/ä»»åŠ¡åï¼Œè‹¥ä¸æ˜ç¡®å°±ç”¨ 'unknown'>",
  "current_state": "<string: ä¾‹å¦‚ setup_in_progress / cluster_ok_tested / build_failed ç­‰>",
  "goals": ["<string>", "..."],
  "constraints": ["<string>", "..."],
  "environment": {
    "os": "<string|null>",
    "runtime": "<string|null>",
    "tools": ["<string>", "..."],
    "paths": ["<string>", "..."]
  },
  "verified_facts": ["<string>", "..."],
  "next_actions": ["<string>", "..."],
  "detail_index": {
    "resolutions": [
      {
        "id": "res-001",
        "problem_signature": "<string: å¯ç”¨äºåŒ¹é…æ—¥å¿—/æŠ¥é”™çš„ç¨³å®šå…³é”®è¯>",
        "summary": "<string: ä¸€å¥è¯æœ€ç»ˆæ­£ç¡®æ–¹æ¡ˆ>",
        "tags": ["<string>", "..."],
        "artifacts_touched": ["<string>", "..."]
      }
    ]
  }
}

çº¦æŸï¼š
- detail_index åªæ”¶å½• resolutionsï¼ˆæœ¬ä»»åŠ¡åªäº§å‡º index+resolutionsï¼‰
- artifacts_touched åªå†™æ–‡ä»¶è·¯å¾„/ç»„ä»¶åï¼Œä¸è¦è´´æ–‡ä»¶å†…å®¹
- verified_facts å¿…é¡»æ˜¯â€œå·²ç»ç¡®è®¤â€çš„äº‹å®ï¼Œä¸è¦çŒœæµ‹
- goals/constraints/environment è‹¥è¾“å…¥æ²¡æœ‰å°±ç•™ç©ºæ•°ç»„æˆ– nullï¼Œä½†å­—æ®µå¿…é¡»å­˜åœ¨

ã€resolutions.ndjson Schemaã€‘
resolutions.ndjson æ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡ï¼Œå­—æ®µå¦‚ä¸‹ï¼ˆæ¯æ¡éƒ½å¿…é¡»å®Œæ•´ï¼‰ï¼š
{
  "id": "res-001",
  "type": "resolution",
  "problem_signature": "<string>",
  "problem": "<string: ç°è±¡/æŠ¥é”™>",
  "root_cause": "<string: æœ€ç»ˆåŸå› >",
  "final_fix": ["<string step>", "..."],
  "why_it_works": "<string>",
  "verification": ["<string check>", "..."],
  "anti_patterns": ["<string>", "..."],
  "artifacts_touched": ["<string>", "..."],
  "evidence": {
    "signals": ["<string: æ¥è‡ªå¯¹è¯çš„å…³é”®è¯æ®ï¼Œå¦‚ 'cluster_state:ok' æˆ– '[OK] All 16384 slots covered'>", "..."],
    "when": "<string|null: è‹¥å¯¹è¯é‡Œæœ‰æ—¥æœŸæ—¶é—´å°±å¡«ï¼Œå¦åˆ™ null>"
  }
}

çº¦æŸï¼š
- final_fix ä¸ verification å¿…é¡»å¯æ‰§è¡Œ/å¯éªŒè¯ï¼ˆæ­¥éª¤æ¸…æ™°ï¼‰
- anti_patterns æœ€å°‘ 1 æ¡ï¼Œæœ€å¤š 3 æ¡
- evidence.signals ç”¨æ¥å­˜â€œæˆåŠŸåˆ¤æ®/å…³é”® log ç‰‡æ®µâ€ï¼Œä¸è¦è´´é•¿æ—¥å¿—ï¼ˆæ¯æ¡â‰¤120å­—ç¬¦ï¼‰
- id ä» res-001 é€’å¢ï¼Œä¸è·³å·

ã€æå–ç­–ç•¥ã€‘
- å¦‚æœåŒä¸€ä¸ªé—®é¢˜å‡ºç°å¤šæ¬¡å°è¯•ï¼Œä»¥â€œæœ€åæˆåŠŸçš„é‚£æ¡è·¯å¾„â€ä¸ºå‡†å†™ final_fix
- å¦‚æœå¯¹è¯æ²¡æœ‰æ˜ç¡®æˆåŠŸè¯æ®ï¼Œå°±ä¸è¦ç¼–é€  verified_factsï¼›ç›¸åº” resolution çš„ evidence.signals ä¹Ÿè¦è°¨æ…
- problem_signature ä¼˜å…ˆå–ç¨³å®šæŠ¥é”™å…³é”®è¯ï¼Œå¦‚ï¼š
  - "Pool overlaps with other one"
  - "the input device is not a TTY"
  - "CROSSSLOT Keys in request"
  - "container name already in use"
  - "cluster_state:ok"
- tags ç”¨å°å†™çŸ­è¯ï¼šdocker/compose/redis/network/windows/tty/cleanup/cluster/slots ç­‰

ç°åœ¨å¼€å§‹å¤„ç†ç”¨æˆ·æä¾›çš„å¯¹è¯æ–‡æœ¬ï¼Œå¹¶æŒ‰ä¸Šè¿°æ ¼å¼ç›´æ¥è¾“å‡ºä¸¤ä¸ªæ–‡ä»¶å—ã€‚
    """).strip()

    engine = "claude-cli"
    model_out = ""
    index_err = None
    try:
        model_out = run_claude_p(summary_prompt, "ã€ä¼šè¯ç´ æã€‘\n" + material)
        # è§£ææ¨¡å‹è¾“å‡ºå¹¶å†™å…¥ .claude/context/...
        claude_dir = os.path.join(base_dir, ".claude")
        parse_model_output_to_context(model_out, claude_dir)
    except Exception as ex:
        engine = "error"
        index_err = str(ex)

    # å›ºå®šå†™ debug æ–‡ä»¶ï¼Œä¾¿äºæ’é”™ï¼ˆä¸å†éœ€è¦ç”¨æˆ·æŒ‡å®šè¾“å‡ºæ–‡ä»¶ï¼‰
    now = datetime.now().isoformat(timespec="seconds").replace(":", "-")
    debug_path = os.path.join(debug_dir, f"save-summary-{now}.md")
    with open(debug_path, "w", encoding="utf-8") as f:

        f.write(f"<!-- saved: {now} | engine: {engine} -->\n\n")

        f.write("# Hook åŸå§‹è¾“å…¥ï¼ˆstdin åŸæ–‡ï¼‰\n\n```json\n")
        f.write(raw_stdin.rstrip() + "\n")
        f.write("```\n\n")

        f.write("# transcript_path\n\n")
        f.write(f"`{transcript_path}`\n\n")

        f.write("# ä¼šè¯ç´ æï¼ˆç»™æ¨¡å‹çœ‹çš„è¾“å…¥ï¼‰\n\n```text\n")
        f.write(material.rstrip() + "\n")
        f.write("```\n\n")

        f.write("# æ¨¡å‹åŸå§‹è¾“å‡ºï¼ˆç”¨äºå½’æ¡£è§£æï¼‰\n\n```text\n")
        f.write((model_out or "").rstrip() + "\n")
        f.write("```\n\n")

        if index_err:
            f.write("# è§£æ/è½ç›˜é”™è¯¯\n\n")
            f.write(index_err + "\n")
    if engine == "error":
        eprint(f"âš ï¸ /save-summary å¤±è´¥ï¼š{index_err}\nè°ƒè¯•æ–‡ä»¶ï¼š{debug_path}")
    else:
        
        # è®¡ç®—ä¸€ä¸‹æ–‡ä»¶è·¯å¾„
        context_path = os.path.join(claude_dir, 'context')
        
        eprint(f"\n{Colors.GREEN}âœ” [SYSTEM SYNC] Archive Successful.{Colors.ENDC}")
        eprint(f"{Colors.BOLD}ğŸ“‚ Context Updated: {Colors.ENDC}{context_path}")
        eprint(f"{Colors.BOLD}ğŸ“ Debug Log:      {Colors.ENDC}{os.path.basename(debug_path)}")

    sys.exit(2)

if __name__ == "__main__":
    sys.stderr.write(
        f"DEBUG env: "
        f"CLAUDE_PLUGIN_ROOT={os.environ.get('CLAUDE_PLUGIN_ROOT')}, "
        f"CLAUDE_PROJECT_DIR={os.environ.get('CLAUDE_PROJECT_DIR')}\n"
        )
    main()
